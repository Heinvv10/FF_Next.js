# VLM Integration for DR Photo Evaluation - Complete Summary

## ‚úÖ What Was Accomplished

Successfully integrated **MiniCPM-V-2_6** Vision Language Model for automated DR (Drop Record) photo quality evaluation.

### 1. VLM Service Implementation (`src/modules/foto-review/services/fotoVlmService.ts`)

Created a complete VLM integration service with:

- **Photo fetching** from BOSS API (http://72.61.197.178:8001)
- **Base64 encoding** (required by vLLM API)
- **Batch processing** to handle context limits (5 photos per batch)
- **11 QA steps evaluation** based on DR_PHOTO_VERIFICATION_FIBERTIME_ALIGNED.md
- **OpenAI-compatible API** calls to vLLM
- **Result merging** from multiple batches
- **Error handling** and logging
- **Health checks** for VLM service

### 2. API Integration (`pages/api/foto/evaluate.ts`)

Updated evaluate API to:
- **Primary method**: VLM via MiniCPM-V-2_6
- **Fallback**: Python backend if VLM fails
- **Fallback**: Mock data if both fail
- Return evaluation method used

### 3. Production Deployment

Deployed to Velocity Server:
- **URL**: http://velo-server:3005/foto-review
- **VLM Endpoint**: http://100.96.203.105:8100/v1/chat/completions
- **Model**: openbmb/MiniCPM-V-2_6
- **Environment**: `.env.production` configured

## üìã 11 QA Steps Evaluated

The VLM evaluates photos against these fiber installation quality steps:

1. **House Photo** - Address/street number visible
2. **Cable Span from Pole** - Aerial fiber drop documentation
3. **Cable Entry Outside** - External entry point
4. **Cable Entry Inside** - Internal cable routing
5. **Wall for Installation** - ONT mounting location
6. **ONT Back After Install** - Connection verification
7. **Power Meter Reading** - Signal strength confirmation
8. **ONT Barcode** - Asset tracking (serial number)
9. **UPS Serial Number** - Backup power asset tracking
10. **Final Installation** - Complete setup verification
11. **Green Lights on ONT** - Operational confirmation

## üîß Architecture

```
User clicks "Evaluate with AI" on foto-review page
  ‚Üì
Frontend (foto-review.tsx)
  ‚Üì
API (/api/foto/evaluate)
  ‚Üì
VLM Service (fotoVlmService.ts)
  ‚Üì
  1. Fetch DR photos from BOSS API
  2. Convert each photo to base64
  3. Split into batches of 5 photos (context limit)
  4. For each batch:
     - Build evaluation prompt with QA steps
     - Send to MiniCPM-V-2_6 at port 8100
     - Parse JSON evaluation response
  5. Merge batch results (average scores, count passes)
  6. Save to database
  ‚Üì
Response with overall PASS/FAIL + detailed step results
```

## ‚öôÔ∏è Configuration

### Environment Variables (`.env.production`)

```bash
# VLM Configuration
VLM_API_URL=http://100.96.203.105:8100
VLM_MODEL=openbmb/MiniCPM-V-2_6

# BOSS API (photo source)
BOSS_VPS_API_URL=http://72.61.197.178:8001

# Feature Flags
USE_VLM_BACKEND=true              # Enable VLM (default: true)
USE_PYTHON_BACKEND=false          # Python fallback (optional)
```

### Key Settings

- **Batch Size**: 5 photos per batch (to stay within 4096 token context limit)
- **Timeout**: 180 seconds (3 minutes) for complete evaluation
- **Temperature**: 0.1 (low for consistent, factual evaluation)
- **Max Tokens**: 2000 per response

## üìä Performance

### Current Performance
- **16 photos**: ~2-3 minutes (4 batches of 5+5+5+1)
- **Per batch**: ~30-45 seconds
- **Breakdown**:
  - Photo fetching: 5-10 seconds
  - Base64 encoding: 2-3 seconds
  - VLM processing: 20-30 seconds per batch
  - Result merging: <1 second

### Bottlenecks
1. **Sequential batch processing** - Batches run one at a time
2. **Base64 encoding** - Large images add overhead
3. **VLM model loading** - First request slower (model warmup)
4. **Network latency** - Fetching photos from BOSS API

## üöÄ Optimization Recommendations

### Short-term (Easy Wins)

1. **Parallel batch processing**
   ```typescript
   // Instead of: for (batch of batches) { await evaluate(batch) }
   // Use: await Promise.all(batches.map(batch => evaluate(batch)))
   ```
   **Impact**: 4x faster (30-45 seconds instead of 2-3 minutes)

2. **Image compression before base64**
   ```typescript
   // Resize images to max 800px width before encoding
   // Reduces payload size by 70-80%
   ```
   **Impact**: 30% faster VLM processing

3. **Selective photo evaluation**
   ```typescript
   // Only send critical QA steps (e.g., ONT barcode, green lights, power meter)
   // Instead of all 16 photos, send 6-8 most important
   ```
   **Impact**: 2x faster, reduces batches from 4 to 2

### Medium-term (Performance)

4. **Photo caching**
   - Cache base64-encoded photos for 1 hour
   - Skip re-encoding for repeated evaluations
   - **Impact**: 40% faster on re-evaluations

5. **Increase VLM context limit**
   - Configure vLLM with `--max-model-len 8192`
   - Process all photos in 2 batches instead of 4
   - **Impact**: 50% faster

6. **Streaming responses**
   - Use `stream: true` in VLM API calls
   - Show real-time progress to user
   - **Impact**: Better UX, perceived faster

### Long-term (Architecture)

7. **Background processing**
   - Queue evaluations for background processing
   - Notify user when complete (WebSocket/polling)
   - **Impact**: Instant UI response

8. **Edge caching**
   - Cache evaluation results for 24 hours
   - Skip re-evaluation for same DR
   - **Impact**: Instant for cached DRs

9. **Dedicated VLM instance**
   - Fine-tune MiniCPM-V-2_6 specifically for DR photos
   - Optimize model quantization
   - **Impact**: 2-3x faster inference

## üß™ Testing

### Test a DR Evaluation

```bash
# From local machine (via Tailscale)
curl -X POST http://100.96.203.105:3005/api/foto/evaluate \
  -H "Content-Type: application/json" \
  -d '{"dr_number": "DR1730550"}' | jq

# From server
curl -X POST http://localhost:3005/api/foto/evaluate \
  -H "Content-Type: application/json" \
  -d '{"dr_number": "DR1730550"}' | jq
```

### Expected Response

```json
{
  "success": true,
  "method": "vlm",
  "message": "AI evaluation completed successfully using VLM",
  "data": {
    "dr_number": "DR1730550",
    "overall_status": "PASS",
    "average_score": 8.5,
    "total_steps": 11,
    "passed_steps": 10,
    "step_results": [
      {
        "step_number": 1,
        "step_name": "house_photo",
        "step_label": "House Photo",
        "passed": true,
        "score": 9,
        "comment": "Clear photo with visible address"
      },
      // ... 10 more steps
    ],
    "evaluation_date": "2025-12-17T06:00:00.000Z",
    "markdown_report": "Overall assessment and recommendations"
  }
}
```

### Test VLM Health

```bash
curl http://100.96.203.105:8100/v1/models | jq
```

Expected:
```json
{
  "data": [
    {
      "id": "openbmb/MiniCPM-V-2_6",
      "created": 1765950235
    }
  ]
}
```

## üêõ Troubleshooting

### Issue: "Context length exceeded" (400 error)

**Cause**: Too many photos or prompt too long

**Solution**: Reduce batch size in `fotoVlmService.ts`:
```typescript
const BATCH_SIZE = 3; // Was 5
```

### Issue: "VLM API returned 404"

**Cause**: Wrong API endpoint or model name

**Check**:
```bash
# Verify VLM is running
curl http://100.96.203.105:8100/v1/models

# Check environment variables
ssh louis@velo-server
cat ~/apps/fibreflow/.env.production | grep VLM
```

**Fix**:
```bash
# Update environment
sed -i 's|VLM_API_URL=.*|VLM_API_URL=http://100.96.203.105:8100|' .env.production
sed -i 's|VLM_MODEL=.*|VLM_MODEL=openbmb/MiniCPM-V-2_6|' .env.production
```

### Issue: Evaluation timing out

**Cause**: Too many photos, slow VLM inference

**Solution 1 - Increase timeout**:
```typescript
// In fotoVlmService.ts
const VLM_TIMEOUT_MS = 300000; // 5 minutes (was 3)
```

**Solution 2 - Reduce photos**:
```typescript
// Only evaluate critical steps
const criticalPhotos = photoUrls.filter(url =>
  url.includes('ont_barcode') ||
  url.includes('green_lights') ||
  url.includes('power_meter')
);
```

### Issue: "Failed to fetch photos"

**Cause**: BOSS API unreachable or DR not found

**Check**:
```bash
curl http://72.61.197.178:8001/api/photos | jq '.drs[] | select(.dr_number == "DR1730550")'
```

### Issue: VLM returns invalid JSON

**Cause**: Model not following JSON format instruction

**Solution**: Add JSON schema to prompt (already implemented)

### Issue: Memory errors on server

**Cause**: Too many concurrent evaluations, large images

**Check**:
```bash
ssh louis@velo-server
free -h  # Check available memory
top  # Check if vLLM is using too much RAM
```

**Solution**: Limit concurrent evaluations or restart vLLM

## üìù Logging

Check evaluation logs:
```bash
ssh louis@velo-server
tail -f ~/fibreflow.log | grep -E "VlmService|evaluate"
```

Look for:
- `Starting VLM evaluation for DR...`
- `Fetched N photos for DR...`
- `Processing N batches of photos`
- `Evaluating batch X/Y`
- `VLM evaluation completed: PASS/FAIL`

## üîÑ Maintenance

### Restart Services

```bash
ssh louis@velo-server

# Restart Next.js app
pkill -f "next"
cd ~/apps/fibreflow
PORT=3005 npm start

# Restart VLM (if needed)
sudo systemctl restart vllm
# OR check what's managing it
ps aux | grep vllm
```

### Update VLM Integration

```bash
# Local development
cd /home/louisdup/VF/Apps/FF_React
git pull
npm install
npm run build

# Deploy to production
git push origin master

# On server
ssh louis@velo-server
cd ~/apps/fibreflow
git pull origin master
npm run build
pkill -f "next"
PORT=3005 npm start
```

## üìñ Related Documentation

- **DR Verification Manual**: `/home/louisdup/Downloads/DR_PHOTO_VERIFICATION_FIBERTIME_ALIGNED.md`
- **VLM API Docs**: http://100.96.203.105:8100/docs
- **BOSS API**: http://72.61.197.178:8001/docs (if available)

## üéØ Next Steps

1. **Implement parallel batch processing** (biggest performance win)
2. **Add progress indicators** in UI
3. **Monitor evaluation quality** - track accuracy vs manual reviews
4. **Fine-tune prompts** based on evaluation results
5. **Add evaluation caching** to avoid redundant processing
6. **Create dashboard** for evaluation analytics

## ‚úÖ Success Criteria Met

- ‚úÖ VLM integrated with MiniCPM-V-2_6
- ‚úÖ 11 QA steps evaluated automatically
- ‚úÖ Deployed to production at http://velo-server:3005
- ‚úÖ Handles context limits with batching
- ‚úÖ Error handling and fallbacks in place
- ‚úÖ Evaluation results saved to database
- ‚úÖ User can trigger evaluation from foto-review page

## üö® Known Limitations

1. **Slow performance**: 2-3 minutes for 16 photos (can be optimized)
2. **Sequential processing**: Batches run one at a time
3. **No caching**: Re-evaluates same DR every time
4. **No progress feedback**: User waits with no updates
5. **Context limits**: Max 5 photos per batch (4096 tokens)

---

**Integration Date**: December 17, 2025
**Model**: openbmb/MiniCPM-V-2_6
**Status**: ‚úÖ Production Ready (with performance optimization needed)
